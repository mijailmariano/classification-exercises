{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Exercises\n",
    "    start: thursday, July 7th 2022\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing DS libraries/modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import env\n",
    "from env import user, password, host, get_connection\n",
    "\n",
    "import prepare\n",
    "from acquire import get_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree and Model Evaluation Imports\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Exercise #1:\n",
    "\n",
    "**Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:**\n",
    "\n",
    "1. What is your baseline prediction? \n",
    "2. What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). \n",
    "3. When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### <u>Dataset familiarization / cleaning:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing titanic dataset from \"acquire.py\" file\n",
    "\n",
    "titanic_df = get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  891 non-null    int64  \n",
      " 1   survived      891 non-null    int64  \n",
      " 2   pclass        891 non-null    int64  \n",
      " 3   sex           891 non-null    object \n",
      " 4   age           714 non-null    float64\n",
      " 5   sibsp         891 non-null    int64  \n",
      " 6   parch         891 non-null    int64  \n",
      " 7   fare          891 non-null    float64\n",
      " 8   embarked      889 non-null    object \n",
      " 9   class         891 non-null    object \n",
      " 10  deck          203 non-null    object \n",
      " 11  embark_town   889 non-null    object \n",
      " 12  alone         891 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id    0.00\n",
       "survived        0.00\n",
       "pclass          0.00\n",
       "sex             0.00\n",
       "age             0.20\n",
       "sibsp           0.00\n",
       "parch           0.00\n",
       "fare            0.00\n",
       "embarked        0.00\n",
       "class           0.00\n",
       "deck            0.77\n",
       "embark_town     0.00\n",
       "alone           0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the percentage of missing values per column - where:\n",
    "# ~20% of \"age\" column values are missing\n",
    "# ~77% of \"deck\" column values are missing\n",
    "\n",
    "# i will create a copy of the dataframe and elect to remove these columns due to the relatively high percentage of NULL values\n",
    "\n",
    "round(titanic_df.isna().mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a copy of the titanic dataframe:\n",
    "\n",
    "titanic_copy = titanic_df.copy()\n",
    "titanic_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also removing passenger_id (not needed for analysis), pclass (duplicated column), and embarked (duplicated column)\n",
    "\n",
    "titanic_copy = titanic_copy.drop(columns=[\"passenger_id\", \"age\", \"deck\", \"embarked\", \"pclass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex  sibsp  parch     fare  class  embark_town  alone\n",
       "0         0    male      1      0   7.2500  Third  Southampton      0\n",
       "1         1  female      1      0  71.2833  First    Cherbourg      0\n",
       "2         1  female      0      0   7.9250  Third  Southampton      1\n",
       "3         1  female      1      0  53.1000  First  Southampton      0\n",
       "4         0    male      0      0   8.0500  Third  Southampton      1"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy.head() # checks out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 4, 2, 5, 8])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy[\"sibsp\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>siblings_or_spouse</th>\n",
       "      <th>parent_or_children</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex  siblings_or_spouse  parent_or_children     fare  class  \\\n",
       "0         0    male                   1                   0   7.2500  Third   \n",
       "1         1  female                   1                   0  71.2833  First   \n",
       "2         1  female                   0                   0   7.9250  Third   \n",
       "3         1  female                   1                   0  53.1000  First   \n",
       "4         0    male                   0                   0   8.0500  Third   \n",
       "\n",
       "   embark_town  alone  \n",
       "0  Southampton      0  \n",
       "1    Cherbourg      0  \n",
       "2  Southampton      1  \n",
       "3  Southampton      0  \n",
       "4  Southampton      1  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming columns for clarity -- \n",
    "\n",
    "titanic_copy = titanic_copy.rename(columns = {\"sibsp\": \"siblings_or_spouse\", \"parch\": \"parent_or_children\"})\n",
    "titanic_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>siblings_or_spouse</th>\n",
       "      <th>parent_or_children</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.28</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.10</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex  siblings_or_spouse  parent_or_children   fare  class  \\\n",
       "0         0    male                   1                   0   7.25  Third   \n",
       "1         1  female                   1                   0  71.28  First   \n",
       "2         1  female                   0                   0   7.92  Third   \n",
       "3         1  female                   1                   0  53.10  First   \n",
       "4         0    male                   0                   0   8.05  Third   \n",
       "\n",
       "   embark_town  alone  \n",
       "0  Southampton      0  \n",
       "1    Cherbourg      0  \n",
       "2  Southampton      1  \n",
       "3  Southampton      0  \n",
       "4  Southampton      1  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rounding the fare column values to two (2) decimal places\n",
    "\n",
    "titanic_copy[\"fare\"] = titanic_copy[\"fare\"].round(2)\n",
    "titanic_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived                int64\n",
       "sex                    object\n",
       "siblings_or_spouse      int64\n",
       "parent_or_children      int64\n",
       "fare                  float64\n",
       "class                  object\n",
       "embark_town            object\n",
       "alone                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying column value types - \n",
    "\n",
    "titanic_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'class', 'embark_town'], dtype='object')"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dummy variables of categorical values\n",
    "\n",
    "titanic_copy.select_dtypes(include = \"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>siblings_or_spouse</th>\n",
       "      <th>parent_or_children</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  siblings_or_spouse  parent_or_children   fare  alone  sex_female  \\\n",
       "0         0                   1                   0   7.25      0           0   \n",
       "1         1                   1                   0  71.28      0           1   \n",
       "2         1                   0                   0   7.92      1           1   \n",
       "3         1                   1                   0  53.10      0           1   \n",
       "4         0                   0                   0   8.05      1           0   \n",
       "\n",
       "   sex_male  class_First  class_Second  class_Third  embark_town_Cherbourg  \\\n",
       "0         1            0             0            1                      0   \n",
       "1         0            1             0            0                      1   \n",
       "2         0            0             0            1                      0   \n",
       "3         0            1             0            0                      0   \n",
       "4         1            0             0            1                      0   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                       0                        1  \n",
       "1                       0                        0  \n",
       "2                       0                        1  \n",
       "3                       0                        1  \n",
       "4                       0                        1  "
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy = pd.get_dummies(titanic_copy, columns = ['sex', 'class', 'embark_town'])\n",
    "titanic_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Splitting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    '''\n",
    "    Takes in a dataframe and return train, validate, test subset dataframes\n",
    "    '''\n",
    "    train, test = train_test_split(df, test_size = 0.2, random_state=123, stratify = df.sex_male)\n",
    "    train, validate = train_test_split(train, test_size= 0.25, random_state=123, stratify = train.sex_male)\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (534, 13)\n",
      "Validate dataset shape: (178, 13)\n",
      "Test dataset shape: (179, 13)\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = split_data(titanic_copy)\n",
    "\n",
    "print(f\"Train dataset shape: {train.shape}\")\n",
    "print(f\"Validate dataset shape: {validate.shape}\")\n",
    "print(f\"Test dataset shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "1. What is your baseline prediction? \n",
    "2. What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). \n",
    "3. When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. what is the baseline prediction? \n",
    "\n",
    "**<u>notes:</u>**\n",
    "\n",
    "- We are predicting passenger \"survival\"\n",
    "\n",
    "**Survival:**\n",
    "\n",
    "0 = Did NOT survive\n",
    "\n",
    "1 = Did survive\n",
    "\n",
    "True Positive: predict survived --> (actual) survived\n",
    "True Negative: predict did NOT survive --> (actual) did NOT survive\n",
    "False Positive: predict survived --> (actual) did NOT survive\n",
    "False Negative: predict did NOT survive --> (actual) survived "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    327\n",
       "1    207\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>siblings_or_spouse</th>\n",
       "      <th>parent_or_children</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  siblings_or_spouse  parent_or_children   fare  alone  \\\n",
       "142         1                   1                   0  15.85      0   \n",
       "827         1                   0                   2  37.00      0   \n",
       "865         1                   0                   0  13.00      1   \n",
       "531         0                   0                   0   7.23      1   \n",
       "292         0                   0                   0  12.88      1   \n",
       "\n",
       "     sex_female  sex_male  class_First  class_Second  class_Third  \\\n",
       "142           1         0            0             0            1   \n",
       "827           0         1            0             1            0   \n",
       "865           1         0            0             1            0   \n",
       "531           0         1            0             0            1   \n",
       "292           0         1            0             1            0   \n",
       "\n",
       "     embark_town_Cherbourg  embark_town_Queenstown  embark_town_Southampton  \\\n",
       "142                      0                       0                        1   \n",
       "827                      1                       0                        0   \n",
       "865                      0                       0                        1   \n",
       "531                      1                       0                        0   \n",
       "292                      1                       0                        0   \n",
       "\n",
       "     baseline_prediction  \n",
       "142                    0  \n",
       "827                    0  \n",
       "865                    0  \n",
       "531                    0  \n",
       "292                    0  "
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline prediction = highest frequency outcome \"did NOT survive\" or 0\n",
    "\n",
    "train[\"baseline_prediction\"] = 0\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: % 61.0\n"
     ]
    }
   ],
   "source": [
    "# baseline accuracy = ~61% accuracy\n",
    "\n",
    "baseline_acc = (train[\"baseline_prediction\"] == train[\"survived\"]).mean().round(3)\n",
    "print(f\"Baseline Accuracy: % {(baseline_acc * 100).round()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived               int64\n",
       "baseline_prediction    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[[\"survived\", \"baseline_prediction\"]].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Exercise #2:\n",
    "\n",
    "Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived                   1.000000\n",
       "siblings_or_spouse        -0.061114\n",
       "parent_or_children         0.028207\n",
       "fare                       0.223605\n",
       "alone                     -0.174404\n",
       "sex_female                 0.475802\n",
       "sex_male                  -0.475802\n",
       "class_First                0.275963\n",
       "class_Second               0.102282\n",
       "class_Third               -0.322787\n",
       "embark_town_Cherbourg      0.119265\n",
       "embark_town_Queenstown     0.027172\n",
       "embark_town_Southampton   -0.131472\n",
       "baseline_prediction             NaN\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick correlation test\n",
    "\n",
    "train.corr(method = \"pearson\").iloc[0] # since i know survived is the fist column, i can use the iloc[0], meaning return correlation to the \"survived\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions:**\n",
    "\n",
    "Given the **<u>correlation coefficient</u>** of ea. column/feature to \"survival\" outcome, i conclude that a passenger's sex, class, and fare amount have a greater impact in predicting a passenger's survival.\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'siblings_or_spouse', 'parent_or_children', 'fare', 'alone',\n",
       "       'sex_female', 'sex_male', 'class_First', 'class_Second', 'class_Third',\n",
       "       'embark_town_Cherbourg', 'embark_town_Queenstown',\n",
       "       'embark_town_Southampton', 'baseline_prediction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the columns that are most correlated to survival outcome\n",
    "X = train[[ \n",
    "    'fare', \\\n",
    "    'sex_female', \\\n",
    "    'sex_male', \\\n",
    "    'class_First', \\\n",
    "    'class_Second', \\\n",
    "    'class_Third']]\n",
    "\n",
    "y = train[\"survived\"]\n",
    "\n",
    "X_train_and_validate, X_test, y_train_and_validate, y_test = train_test_split(X, y, random_state=123, test_size=.3)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_and_validate, y_train_and_validate, random_state=123, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>7.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>51.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>15.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>14.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>26.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fare  sex_female  sex_male  class_First  class_Second  class_Third\n",
       "459   7.75           0         1            0             0            1\n",
       "571  51.48           1         0            1             0            0\n",
       "381  15.74           1         0            0             0            1\n",
       "240  14.45           1         0            0             0            1\n",
       "312  26.00           1         0            0             1            0"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459    0\n",
       "571    1\n",
       "381    1\n",
       "240    0\n",
       "312    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    184\n",
       "1    114\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "* **Exercise #3: Evaluate your in-sample results using the model score, confusion matrix, and classification report**\n",
    "\n",
    "* **Exercise #4: Compute Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support**\n",
    "\n",
    "* **Exercise #5: Run through steps 2-4 using a different max_depth value**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTreeClassifier(max_depth = 3, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = tree1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the small tree\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree1, feature_names = X_train.columns.astype(\"str\"), class_names = y_train.unique().astype(\"str\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifer on training dataset: % 0.78\n"
     ]
    }
   ],
   "source": [
    "# evaluating the initial train dataset/tree1 performance\n",
    "\n",
    "print('Accuracy of Decision Tree Classifer on training dataset: % {:.2f}'.format(tree1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa2d0be2b50>"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting confusion matrices for small and big tree models:\n",
    "%matplotlib inline\n",
    "\n",
    "plot_confusion_matrix(tree1, X_train, y_train, display_labels=['Did NOT Survive', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84       184\n",
      "           1       0.86      0.50      0.63       114\n",
      "\n",
      "    accuracy                           0.78       298\n",
      "   macro avg       0.81      0.73      0.74       298\n",
      "weighted avg       0.80      0.78      0.76       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# returning the classification report:\n",
    "\n",
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.808973</td>\n",
       "      <td>0.796133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.725543</td>\n",
       "      <td>0.778523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.737340</td>\n",
       "      <td>0.761771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>184.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>298.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.754310    0.863636  0.778523    0.808973      0.796133\n",
       "recall       0.951087    0.500000  0.778523    0.725543      0.778523\n",
       "f1-score     0.841346    0.633333  0.778523    0.737340      0.761771\n",
       "support    184.000000  114.000000  0.778523  298.000000    298.000000"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Finding \"optimal\" max_depth for decision tree & evaluating the model's performance on the train dataset first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of: 1\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.778351    0.682692  0.744966    0.730521      0.741756\n",
      "recall       0.820652    0.622807  0.744966    0.721730      0.744966\n",
      "f1-score     0.798942    0.651376  0.744966    0.725159      0.742491\n",
      "support    184.000000  114.000000  0.744966  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.724696    0.901961  0.755034    0.813329      0.792509\n",
      "recall       0.972826    0.403509  0.755034    0.688167      0.755034\n",
      "f1-score     0.830626    0.557576  0.755034    0.694101      0.726171\n",
      "support    184.000000  114.000000  0.755034  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.754310    0.863636  0.778523    0.808973      0.796133\n",
      "recall       0.951087    0.500000  0.778523    0.725543      0.778523\n",
      "f1-score     0.841346    0.633333  0.778523    0.737340      0.761771\n",
      "support    184.000000  114.000000  0.778523  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.786047    0.819277  0.795302    0.802662      0.798759\n",
      "recall       0.918478    0.596491  0.795302    0.757485      0.795302\n",
      "f1-score     0.847118    0.690355  0.795302    0.768737      0.787148\n",
      "support    184.000000  114.000000  0.795302  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.826531    0.784314  0.812081    0.805422      0.810381\n",
      "recall       0.880435    0.701754  0.812081    0.791095      0.812081\n",
      "f1-score     0.852632    0.740741  0.812081    0.796686      0.809828\n",
      "support    184.000000  114.000000  0.812081  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.811060    0.901235   0.83557    0.856147      0.845556\n",
      "recall       0.956522    0.640351   0.83557    0.798436      0.835570\n",
      "f1-score     0.877805    0.748718   0.83557    0.813262      0.828423\n",
      "support    184.000000  114.000000   0.83557  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.867725    0.816514  0.848993    0.842119      0.848134\n",
      "recall       0.891304    0.780702  0.848993    0.836003      0.848993\n",
      "f1-score     0.879357    0.798206  0.848993    0.838781      0.848312\n",
      "support    184.000000  114.000000  0.848993  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.831776    0.928571   0.85906    0.880174      0.868805\n",
      "recall       0.967391    0.684211   0.85906    0.825801      0.859060\n",
      "f1-score     0.894472    0.787879   0.85906    0.841176      0.853695\n",
      "support    184.000000  114.000000   0.85906  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.841121    0.952381  0.872483    0.896751      0.883684\n",
      "recall       0.978261    0.701754  0.872483    0.840008      0.872483\n",
      "f1-score     0.904523    0.808081  0.872483    0.856302      0.867629\n",
      "support    184.000000  114.000000  0.872483  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.886598    0.884615  0.885906    0.885607      0.885840\n",
      "recall       0.934783    0.807018  0.885906    0.870900      0.885906\n",
      "f1-score     0.910053    0.844037  0.885906    0.877045      0.884798\n",
      "support    184.000000  114.000000  0.885906  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 11\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.876238    0.927083  0.892617    0.901660      0.895689\n",
      "recall       0.961957    0.780702  0.892617    0.871329      0.892617\n",
      "f1-score     0.917098    0.847619  0.892617    0.882359      0.890519\n",
      "support    184.000000  114.000000  0.892617  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 12\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.869565    0.956044  0.895973    0.912805      0.902648\n",
      "recall       0.978261    0.763158  0.895973    0.870709      0.895973\n",
      "f1-score     0.920716    0.848780  0.895973    0.884748      0.893197\n",
      "support    184.000000  114.000000  0.895973  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 13\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.881188    0.937500  0.899329    0.909344      0.902730\n",
      "recall       0.967391    0.789474  0.899329    0.878432      0.899329\n",
      "f1-score     0.922280    0.857143  0.899329    0.889711      0.897362\n",
      "support    184.000000  114.000000  0.899329  298.000000    298.000000\n",
      "\n",
      "Tree with max depth of: 14\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.878049    0.956989  0.902685    0.917519      0.908247\n",
      "recall       0.978261    0.780702  0.902685    0.879481      0.902685\n",
      "f1-score     0.925450    0.859903  0.902685    0.892677      0.900375\n",
      "support    184.000000  114.000000  0.902685  298.000000    298.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using for loops to create classification reports for all depth 1-15\n",
    "\n",
    "for i in range(1, 15):\n",
    "    # Making the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fitting the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Using the model\n",
    "    # We'll evaluate the model's performance on train, first:\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of: {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "\n",
    "    print() # printing a indented line for ea. iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "    where a model depth of 15 produces a \"relative\" max accuracy of ~91% \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing in-sample data (train) to out-sample date (validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>percent_change_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.76</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.73</td>\n",
       "      <td>12.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.68</td>\n",
       "      <td>19.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.72</td>\n",
       "      <td>16.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.71</td>\n",
       "      <td>19.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.68</td>\n",
       "      <td>23.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.68</td>\n",
       "      <td>23.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.69</td>\n",
       "      <td>22.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "      <td>24.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.69</td>\n",
       "      <td>23.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>24.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.69</td>\n",
       "      <td>23.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.69</td>\n",
       "      <td>23.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.69</td>\n",
       "      <td>23.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.69</td>\n",
       "      <td>23.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  percent_change_diff\n",
       "0           1            0.74               0.73                 1.56\n",
       "1           2            0.76               0.72                 4.64\n",
       "2           3            0.78               0.77                 0.67\n",
       "3           4            0.80               0.75                 6.12\n",
       "4           5            0.81               0.76                 6.41\n",
       "5           6            0.84               0.73                12.24\n",
       "6           7            0.85               0.68                19.91\n",
       "7           8            0.86               0.72                16.19\n",
       "8           9            0.87               0.71                19.01\n",
       "9          10            0.89               0.68                23.24\n",
       "10         11            0.89               0.68                23.82\n",
       "11         12            0.90               0.69                22.62\n",
       "12         13            0.90               0.68                24.39\n",
       "13         14            0.90               0.69                23.19\n",
       "14         15            0.91               0.68                24.95\n",
       "15         16            0.91               0.69                23.48\n",
       "16         17            0.91               0.69                23.48\n",
       "17         18            0.91               0.69                23.48\n",
       "18         19            0.91               0.69                23.48"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(1, 20):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"percent_change_diff\"] = ((df.train_accuracy - df.validate_accuracy) / df.train_accuracy) * 100\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666671"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowest percentage change difference between in-sample (train) and out-sample (validate)\n",
    "\n",
    "df[\"percent_change_diff\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "It appears that when compared to the in-sample (validate) our model is has a optimal max_depth of three (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Random Forests Module Exercises\n",
    "    start: thursday, July 7th 2022\n",
    "\n",
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# getting necessary imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize': (12.0, 8.0)})\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (534, 13)\n",
      "Validate dataset shape: (178, 13)\n",
      "Test dataset shape: (179, 13)\n"
     ]
    }
   ],
   "source": [
    "# Exercise #1:\n",
    "# fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) \n",
    "# setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10\n",
    "\n",
    "# 1st data split:\n",
    "\n",
    "def split_data(df):\n",
    "    '''\n",
    "    Takes in a dataframe and return train, validate, test subset dataframes\n",
    "    '''\n",
    "    train, test = train_test_split(df, test_size = 0.2, random_state=123, stratify = df.sex_male)\n",
    "    train, validate = train_test_split(train, test_size= 0.25, random_state=123, stratify = train.sex_male)\n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = split_data(titanic_copy)\n",
    "\n",
    "print(f\"Train dataset shape: {train.shape}\")\n",
    "print(f\"Validate dataset shape: {validate.shape}\")\n",
    "print(f\"Test dataset shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd data split:\n",
    "\n",
    "X = train[[ \n",
    "    'fare', \\\n",
    "    'sex_female', \\\n",
    "    'sex_male', \\\n",
    "    'class_First', \\\n",
    "    'class_Second', \\\n",
    "    'class_Third']]\n",
    "\n",
    "y = train[\"survived\"]\n",
    "\n",
    "X_train_and_validate, X_test, y_train_and_validate, y_test = train_test_split(X, y, random_state=123, test_size=.3)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_and_validate, y_train_and_validate, random_state=123, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the \"random forest\" model using the train (independent / dependent variable) dataset\n",
    "# min sample lead = 1\n",
    "# max decision depth = 10\n",
    "# random state = 123\n",
    "\n",
    "# future note: the \"min_samples_leaf\" parameter defaults to 1\n",
    "\n",
    "rf = RandomForestClassifier(min_samples_leaf = 1, max_depth = 10, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._forest.RandomForestClassifier"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the initial model with X_train and y_train data:\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59979932, 0.12701432, 0.11863909, 0.04989429, 0.01919559,\n",
       "       0.08545739])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "sns.set_theme(style = \"dark\")\n",
    "sns.barplot(rf.feature_importances_[sorted_idx], X_train.columns[sorted_idx], orient = \"h\", color = \"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise #2: Evaluate your results using the model score, confusion matrix, and classification report\n",
    "\n",
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82122165, 0.17877835],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08311364, 0.91688636],\n",
       "       [0.75369361, 0.24630639],\n",
       "       [0.55345238, 0.44654762],\n",
       "       [0.39827103, 0.60172897],\n",
       "       [0.0225    , 0.9775    ],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.25117158, 0.74882842],\n",
       "       [0.39657143, 0.60342857],\n",
       "       [0.03      , 0.97      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.79461444, 0.20538556],\n",
       "       [0.21083462, 0.78916538],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.66245763, 0.33754237],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94809524, 0.05190476],\n",
       "       [0.36034127, 0.63965873],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.53986364, 0.46013636],\n",
       "       [0.82122165, 0.17877835],\n",
       "       [0.73407143, 0.26592857],\n",
       "       [0.82122165, 0.17877835],\n",
       "       [0.09467668, 0.90532332],\n",
       "       [0.94809524, 0.05190476],\n",
       "       [0.04      , 0.96      ],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.39480692, 0.60519308],\n",
       "       [0.        , 1.        ],\n",
       "       [0.75      , 0.25      ],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.35659209, 0.64340791],\n",
       "       [0.97791667, 0.02208333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99439222, 0.00560778],\n",
       "       [0.49869573, 0.50130427],\n",
       "       [1.        , 0.        ],\n",
       "       [0.768     , 0.232     ],\n",
       "       [0.49184441, 0.50815559],\n",
       "       [0.97791667, 0.02208333],\n",
       "       [0.94323343, 0.05676657],\n",
       "       [0.33616667, 0.66383333],\n",
       "       [0.74528488, 0.25471512],\n",
       "       [0.88833333, 0.11166667],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [1.        , 0.        ],\n",
       "       [0.51909334, 0.48090666],\n",
       "       [0.36034127, 0.63965873],\n",
       "       [0.05061364, 0.94938636],\n",
       "       [0.35409805, 0.64590195],\n",
       "       [0.95205869, 0.04794131],\n",
       "       [0.64816622, 0.35183378],\n",
       "       [0.85266667, 0.14733333],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.86705211, 0.13294789],\n",
       "       [0.98      , 0.02      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.47021429, 0.52978571],\n",
       "       [0.98439222, 0.01560778],\n",
       "       [0.47021429, 0.52978571],\n",
       "       [0.168693  , 0.831307  ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.93166667, 0.06833333],\n",
       "       [0.35659209, 0.64340791],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.50625   , 0.49375   ],\n",
       "       [0.66998694, 0.33001306],\n",
       "       [0.836     , 0.164     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.037     , 0.963     ],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.35659209, 0.64340791],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.037     , 0.963     ],\n",
       "       [0.928     , 0.072     ],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.51150649, 0.48849351],\n",
       "       [0.55345238, 0.44654762],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.34495455, 0.65504545],\n",
       "       [0.99407143, 0.00592857],\n",
       "       [0.75369361, 0.24630639],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.91762121, 0.08237879],\n",
       "       [0.43830287, 0.56169713],\n",
       "       [0.09467668, 0.90532332],\n",
       "       [0.14720942, 0.85279058],\n",
       "       [1.        , 0.        ],\n",
       "       [0.20550491, 0.79449509],\n",
       "       [0.94242774, 0.05757226],\n",
       "       [0.39428488, 0.60571512],\n",
       "       [0.75369361, 0.24630639],\n",
       "       [0.50542994, 0.49457006],\n",
       "       [0.99439222, 0.00560778],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.88833333, 0.11166667],\n",
       "       [0.24059334, 0.75940666],\n",
       "       [0.35659209, 0.64340791],\n",
       "       [0.80533898, 0.19466102],\n",
       "       [0.65817088, 0.34182912],\n",
       "       [0.65817088, 0.34182912],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.88014744, 0.11985256],\n",
       "       [0.97791667, 0.02208333],\n",
       "       [0.45582079, 0.54417921],\n",
       "       [0.53531299, 0.46468701],\n",
       "       [0.988     , 0.012     ],\n",
       "       [0.54680692, 0.45319308],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94242774, 0.05757226],\n",
       "       [0.61      , 0.39      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.168693  , 0.831307  ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.99661444, 0.00338556],\n",
       "       [0.32      , 0.68      ],\n",
       "       [0.06175   , 0.93825   ],\n",
       "       [0.35659209, 0.64340791],\n",
       "       [0.42      , 0.58      ],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [0.61578993, 0.38421007],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [0.82122165, 0.17877835],\n",
       "       [0.99661444, 0.00338556],\n",
       "       [0.69981205, 0.30018795],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.44633333, 0.55366667],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [0.99407143, 0.00592857],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [0.94323343, 0.05676657],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [1.        , 0.        ],\n",
       "       [0.168693  , 0.831307  ],\n",
       "       [0.168693  , 0.831307  ],\n",
       "       [0.40375758, 0.59624242],\n",
       "       [0.0225    , 0.9775    ],\n",
       "       [0.6375184 , 0.3624816 ],\n",
       "       [0.49869573, 0.50130427],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [0.75369361, 0.24630639],\n",
       "       [0.51150649, 0.48849351],\n",
       "       [0.36151107, 0.63848893],\n",
       "       [0.05219697, 0.94780303],\n",
       "       [0.46789141, 0.53210859],\n",
       "       [0.86156676, 0.13843324],\n",
       "       [0.66998694, 0.33001306],\n",
       "       [0.97247372, 0.02752628],\n",
       "       [0.90666667, 0.09333333],\n",
       "       [0.99407143, 0.00592857],\n",
       "       [0.51150649, 0.48849351],\n",
       "       [0.93166667, 0.06833333],\n",
       "       [0.98407143, 0.01592857],\n",
       "       [0.55345238, 0.44654762],\n",
       "       [0.0225    , 0.9775    ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91762121, 0.08237879],\n",
       "       [0.97338281, 0.02661719],\n",
       "       [0.50542994, 0.49457006],\n",
       "       [0.04      , 0.96      ],\n",
       "       [0.66998694, 0.33001306],\n",
       "       [0.49184441, 0.50815559],\n",
       "       [0.90666667, 0.09333333],\n",
       "       [0.50542994, 0.49457006],\n",
       "       [0.50542994, 0.49457006],\n",
       "       [0.99407143, 0.00592857],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [1.        , 0.        ],\n",
       "       [0.16483333, 0.83516667],\n",
       "       [0.51150649, 0.48849351],\n",
       "       [0.998     , 0.002     ],\n",
       "       [0.55345238, 0.44654762],\n",
       "       [0.037     , 0.963     ],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.44633333, 0.55366667],\n",
       "       [0.94809524, 0.05190476],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99439222, 0.00560778],\n",
       "       [0.87111328, 0.12888672],\n",
       "       [0.7214223 , 0.2785777 ],\n",
       "       [0.39827103, 0.60172897],\n",
       "       [0.50542994, 0.49457006],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.86156676, 0.13843324],\n",
       "       [0.99      , 0.01      ],\n",
       "       [0.03      , 0.97      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.13316667, 0.86683333],\n",
       "       [0.39278111, 0.60721889],\n",
       "       [0.51150649, 0.48849351],\n",
       "       [0.99661444, 0.00338556],\n",
       "       [0.69981205, 0.30018795],\n",
       "       [0.99439222, 0.00560778],\n",
       "       [1.        , 0.        ],\n",
       "       [0.55921557, 0.44078443],\n",
       "       [0.86705211, 0.13294789],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08386364, 0.91613636],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.65817088, 0.34182912],\n",
       "       [0.97738889, 0.02261111],\n",
       "       [0.82122165, 0.17877835],\n",
       "       [0.69981205, 0.30018795],\n",
       "       [0.37666667, 0.62333333],\n",
       "       [0.50542994, 0.49457006],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.998     , 0.002     ],\n",
       "       [0.92979365, 0.07020635],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.77439222, 0.22560778],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [1.        , 0.        ],\n",
       "       [0.82122165, 0.17877835],\n",
       "       [0.168693  , 0.831307  ],\n",
       "       [0.04061364, 0.95938636],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06807251, 0.93192749],\n",
       "       [0.69981205, 0.30018795],\n",
       "       [0.20550491, 0.79449509],\n",
       "       [0.81148317, 0.18851683],\n",
       "       [0.16307143, 0.83692857],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.21083462, 0.78916538],\n",
       "       [0.        , 1.        ],\n",
       "       [0.23176001, 0.76823999],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.69981205, 0.30018795],\n",
       "       [0.99661444, 0.00338556],\n",
       "       [0.        , 1.        ],\n",
       "       [0.168693  , 0.831307  ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.43830287, 0.56169713],\n",
       "       [0.54680692, 0.45319308],\n",
       "       [0.22308333, 0.77691667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64033289, 0.35966711],\n",
       "       [0.03      , 0.97      ],\n",
       "       [0.76466667, 0.23533333],\n",
       "       [0.46789141, 0.53210859],\n",
       "       [0.836     , 0.164     ],\n",
       "       [0.23189141, 0.76810859],\n",
       "       [0.68566388, 0.31433612],\n",
       "       [0.98661444, 0.01338556],\n",
       "       [0.50625   , 0.49375   ],\n",
       "       [0.98661444, 0.01338556],\n",
       "       [0.        , 1.        ],\n",
       "       [0.91762121, 0.08237879],\n",
       "       [0.988     , 0.012     ],\n",
       "       [0.91374452, 0.08625548],\n",
       "       [0.69981205, 0.30018795],\n",
       "       [0.98      , 0.02      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.16307143, 0.83692857],\n",
       "       [0.95205869, 0.04794131],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [0.51150649, 0.48849351],\n",
       "       [0.99661444, 0.00338556],\n",
       "       [0.82122165, 0.17877835],\n",
       "       [0.015     , 0.985     ],\n",
       "       [0.05061364, 0.94938636],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.08386364, 0.91613636],\n",
       "       [0.34674419, 0.65325581],\n",
       "       [0.36172569, 0.63827431],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99887742, 0.00112258],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.89507937, 0.10492063],\n",
       "       [0.6547381 , 0.3452619 ],\n",
       "       [0.06428716, 0.93571284],\n",
       "       [0.27431478, 0.72568522],\n",
       "       [0.35659209, 0.64340791],\n",
       "       [0.36034127, 0.63965873],\n",
       "       [0.99661444, 0.00338556]])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimating the probability of ea. outcome (did NOT survive / survived)\n",
    "\n",
    "y_prediction_probability = rf.predict_proba(X_train)\n",
    "y_prediction_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173  11]\n",
      " [ 17  97]]\n"
     ]
    }
   ],
   "source": [
    "# random forest tree confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "survived    0   1\n",
       "row_0            \n",
       "0         173  17\n",
       "1          11  97"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crosstab method\n",
    "\n",
    "pd.crosstab( y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 173\n",
      "False Negative: 11\n",
      "False Positive: 17\n",
      "True Positive: 97\n"
     ]
    }
   ],
   "source": [
    "# using the numpy.ravel metho to return a 1D array of the input\n",
    "# where:\n",
    "\n",
    "# 0 = \"negative\" and...\n",
    "# 1 = \"positive\"\n",
    "# TN = first value in array\n",
    "# FN = second value in array\n",
    "# FP = third value in array\n",
    "# TP = fourth (last) value in array\n",
    "\n",
    "TN, FN, FP, TP = confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "print(f'True Negative: {TN}')\n",
    "print(f'False Negative: {FN}')\n",
    "print(f'False Positive: {FP}')\n",
    "print(f'True Positive: {TP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* True Positive: 97\n",
    "\n",
    "* True Negative: 173\n",
    "\n",
    "* False Negative: 17\n",
    "\n",
    "* False Positive: 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.91\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model:\n",
    "\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       184\n",
      "           1       0.90      0.85      0.87       114\n",
      "\n",
      "    accuracy                           0.91       298\n",
      "   macro avg       0.90      0.90      0.90       298\n",
      "weighted avg       0.91      0.91      0.91       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a model classification report\n",
    "\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Validating the Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.68\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise #4: Run through steps increasing your min_samples_leaf and decreasing your max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with max_depth of: 10\n",
      "Random Forest with minimum sample leaves of: 1\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.910526    0.898148   0.90604    0.904337      0.905791\n",
      "recall       0.940217    0.850877   0.90604    0.895547      0.906040\n",
      "f1-score     0.925134    0.873874   0.90604    0.899504      0.905524\n",
      "support    184.000000  114.000000   0.90604  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 9\n",
      "Random Forest with minimum sample leaves of: 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.843434    0.830000  0.838926    0.836717      0.838295\n",
      "recall       0.907609    0.728070  0.838926    0.817839      0.838926\n",
      "f1-score     0.874346    0.775701  0.838926    0.825023      0.836609\n",
      "support    184.000000  114.000000  0.838926  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 8\n",
      "Random Forest with minimum sample leaves of: 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.845361    0.807692  0.832215    0.826527      0.830951\n",
      "recall       0.891304    0.736842  0.832215    0.814073      0.832215\n",
      "f1-score     0.867725    0.770642  0.832215    0.819184      0.830586\n",
      "support    184.000000  114.000000  0.832215  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 7\n",
      "Random Forest with minimum sample leaves of: 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.853403    0.803738   0.83557    0.828571      0.834404\n",
      "recall       0.885870    0.754386   0.83557    0.820128      0.835570\n",
      "f1-score     0.869333    0.778281   0.83557    0.823807      0.834501\n",
      "support    184.000000  114.000000   0.83557  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 6\n",
      "Random Forest with minimum sample leaves of: 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.854839    0.776786  0.825503    0.815812      0.824980\n",
      "recall       0.864130    0.763158  0.825503    0.813644      0.825503\n",
      "f1-score     0.859459    0.769912  0.825503    0.814685      0.825203\n",
      "support    184.000000  114.000000  0.825503  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 5\n",
      "Random Forest with minimum sample leaves of: 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.835979    0.761468  0.808725    0.798723      0.807475\n",
      "recall       0.858696    0.728070  0.808725    0.793383      0.808725\n",
      "f1-score     0.847185    0.744395  0.808725    0.795790      0.807862\n",
      "support    184.000000  114.000000  0.808725  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 4\n",
      "Random Forest with minimum sample leaves of: 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.795122    0.774194  0.788591    0.784658      0.787116\n",
      "recall       0.885870    0.631579  0.788591    0.758724      0.788591\n",
      "f1-score     0.838046    0.695652  0.788591    0.766849      0.783573\n",
      "support    184.000000  114.000000  0.788591  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 3\n",
      "Random Forest with minimum sample leaves of: 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.756637    0.819444  0.771812    0.788041      0.780664\n",
      "recall       0.929348    0.517544  0.771812    0.723446      0.771812\n",
      "f1-score     0.834146    0.634409  0.771812    0.734277      0.757737\n",
      "support    184.000000  114.000000  0.771812  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 2\n",
      "Random Forest with minimum sample leaves of: 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.758621    0.684211  0.734899    0.721416      0.730155\n",
      "recall       0.836957    0.570175  0.734899    0.703566      0.734899\n",
      "f1-score     0.795866    0.622010  0.734899    0.708938      0.729357\n",
      "support    184.000000  114.000000  0.734899  298.000000    298.000000\n",
      "\n",
      "Random Forest with max_depth of: 1\n",
      "Random Forest with minimum sample leaves of: 10\n",
      "                    0       1  accuracy   macro avg  weighted avg\n",
      "precision    0.743243    0.75  0.744966    0.746622      0.745828\n",
      "recall       0.896739    0.50  0.744966    0.698370      0.744966\n",
      "f1-score     0.812808    0.60  0.744966    0.706404      0.731398\n",
      "support    184.000000  114.00  0.744966  298.000000    298.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leaf_counter = 0\n",
    "\n",
    "for i in range(10, 0, -1):\n",
    "    # Make the model\n",
    "    rf = RandomForestClassifier(max_depth=i, min_samples_leaf = (leaf_counter + 1), random_state=123)\n",
    "    leaf_counter += 1\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = rf.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Random Forest with max_depth of: {i}\")\n",
    "    print(f\"Random Forest with minimum sample leaves of: {leaf_counter}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaves</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>percent_change_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.68</td>\n",
       "      <td>24.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.69</td>\n",
       "      <td>17.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_sample_leaves  train_accuracy  validate_accuracy  \\\n",
       "0         10                  1            0.91               0.68   \n",
       "1          9                  2            0.84               0.69   \n",
       "2          8                  3            0.83               0.73   \n",
       "3          7                  4            0.84               0.77   \n",
       "4          6                  5            0.83               0.77   \n",
       "5          5                  6            0.81               0.79   \n",
       "6          4                  7            0.79               0.71   \n",
       "7          3                  8            0.77               0.75   \n",
       "8          2                  9            0.73               0.69   \n",
       "9          1                 10            0.74               0.71   \n",
       "\n",
       "   percent_change_diff  \n",
       "0                24.95  \n",
       "1                17.35  \n",
       "2                11.88  \n",
       "3                 7.45  \n",
       "4                 6.32  \n",
       "5                 2.73  \n",
       "6                10.39  \n",
       "7                 3.26  \n",
       "8                 5.66  \n",
       "9                 5.14  "
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measuring the percent change difference acrross train and validate datasets\n",
    "\n",
    "metrics = []\n",
    "counter = 0\n",
    "for i in range(10, 0, -1):\n",
    "    # Make the model\n",
    "    rf = RandomForestClassifier(max_depth=i, min_samples_leaf = (counter + 1), random_state=123)\n",
    "    counter += 1\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = rf.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = rf.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"min_sample_leaves\": counter,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "\n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"percent_change_diff\"] = ((df.train_accuracy - df.validate_accuracy) / df.train_accuracy) * 100\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise #5: What are the differences in the evaluation metrics?  Which performs better on your in-sample data? Why?\n",
    "\n",
    "<u>**After making a few models, which one has the best performance (or closest metrics) on both train and validate?**</u>\n",
    "\n",
    "----\n",
    "\n",
    "**Train dataset accuracy** = ~81%\n",
    "\n",
    "**Validate dataset accuracy** = ~79%\n",
    "\n",
    "**percentage change difference** = ~2.7%\n",
    "\n",
    "**max_depth** = 5\n",
    "\n",
    "**min sample leaves** = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### K-Nearest Neighbor (\"KNN\") Exercises\n",
    "    start: friday, July 8th 2022\n",
    "\n",
    "**Continue working in your model file with the titanic dataset.**\n",
    "\n",
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "4. Run through steps 2-4 setting k to 10\n",
    "\n",
    "5. Run through setps 2-4 setting k to 20\n",
    "\n",
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing KNN module/functions\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (534, 15)\n",
      "Validate dataset shape: (178, 15)\n",
      "Test dataset shape: (179, 15)\n"
     ]
    }
   ],
   "source": [
    "# creating new datasets for testing purity:\n",
    "\n",
    "titanic_df = get_titanic_data()\n",
    "titanic_copy = titanic_df.copy()\n",
    "\n",
    "titanic_copy = pd.get_dummies(titanic_copy, columns = ['sex', 'class', 'embark_town'], drop_first = True)\n",
    "titanic_copy.head()\n",
    "\n",
    "# 1st split:\n",
    "\n",
    "def split_data(df):\n",
    "    '''\n",
    "    Takes in a dataframe and return train, validate, test subset dataframes\n",
    "    '''\n",
    "    train, test = train_test_split(df, test_size = 0.2, random_state=123, stratify = df.sex_male)\n",
    "    train, validate = train_test_split(train, test_size= 0.25, random_state=123, stratify = train.sex_male)\n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = split_data(titanic_copy)\n",
    "\n",
    "print(f\"Train dataset shape: {train.shape}\")\n",
    "print(f\"Validate dataset shape: {validate.shape}\")\n",
    "print(f\"Test dataset shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>deck</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass   age  sibsp  parch     fare embarked deck  \\\n",
       "0             0         0       3  22.0      1      0   7.2500        S  NaN   \n",
       "1             1         1       1  38.0      1      0  71.2833        C    C   \n",
       "2             2         1       3  26.0      0      0   7.9250        S  NaN   \n",
       "3             3         1       1  35.0      1      0  53.1000        S    C   \n",
       "4             4         0       3  35.0      0      0   8.0500        S  NaN   \n",
       "\n",
       "   alone  sex_male  class_Second  class_Third  embark_town_Queenstown  \\\n",
       "0      0         1             0            1                       0   \n",
       "1      0         0             0            0                       0   \n",
       "2      1         0             0            1                       0   \n",
       "3      0         0             0            0                       0   \n",
       "4      1         1             0            1                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data:\n",
    "\n",
    "titanic_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2nd split:\n",
    "\n",
    "X = train[[ \n",
    "    'fare', \\\n",
    "    'sex_male', \\\n",
    "    'class_Second', \\\n",
    "    'class_Third']]\n",
    "\n",
    "y = train[\"survived\"]\n",
    "\n",
    "X_train_and_validate, X_test, y_train_and_validate, y_test = train_test_split(X, y, random_state=123, test_size=.3)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_and_validate, y_train_and_validate, random_state=123, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise #1: Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "# continuing to work with the titanic dataset\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = knn1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.neighbors._classification.KNeighborsClassifier"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying the type of knn1\n",
    "\n",
    "type(knn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = knn1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing the predictions made \n",
    "\n",
    "y_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 163\n",
      "False Negatives: 21\n",
      "False Positives: 30\n",
      "True Positives: 84\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "TN, FN, FP, TP = confusion_matrix(y_train, y_predictions).ravel()\n",
    "\n",
    "print(f'True Negatives: {TN}')\n",
    "print(f'False Negatives: {FN}')\n",
    "print(f'False Positives: {FP}')\n",
    "print(f'True Positives: {TP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "survived    0   1\n",
       "row_0            \n",
       "0         163  30\n",
       "1          21  84"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix using pd.crosstab\n",
    "# index = predicted outcomes\n",
    "# columns = actual outcomes\n",
    "\n",
    "pd.crosstab(y_predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.83\n"
     ]
    }
   ],
   "source": [
    "# calculating the KNN accuracy\n",
    "\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       184\n",
      "           1       0.80      0.74      0.77       114\n",
      "\n",
      "    accuracy                           0.83       298\n",
      "   macro avg       0.82      0.81      0.82       298\n",
      "weighted avg       0.83      0.83      0.83       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the KNN model classification report:\n",
    "\n",
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise #3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model with # of nearest neighbors: 1\n",
      "                    0           1  accuracy  macro avg  weighted avg\n",
      "precision    0.918478    0.868421  0.899329    0.89345      0.899329\n",
      "recall       0.918478    0.868421  0.899329    0.89345      0.899329\n",
      "f1-score     0.918478    0.868421  0.899329    0.89345      0.899329\n",
      "support    184.000000  114.000000  0.899329  298.00000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.767932    0.967213  0.808725    0.867573      0.844167\n",
      "recall       0.989130    0.517544  0.808725    0.753337      0.808725\n",
      "f1-score     0.864608    0.674286  0.808725    0.769447      0.791800\n",
      "support    184.000000  114.000000  0.808725  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.837438    0.852632  0.842282    0.845035      0.843251\n",
      "recall       0.923913    0.710526  0.842282    0.817220      0.842282\n",
      "f1-score     0.878553    0.775120  0.842282    0.826836      0.838985\n",
      "support    184.000000  114.000000  0.842282  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.814286    0.852273  0.825503    0.833279      0.828818\n",
      "recall       0.929348    0.657895  0.825503    0.793621      0.825503\n",
      "f1-score     0.868020    0.742574  0.825503    0.805297      0.820031\n",
      "support    184.000000  114.000000  0.825503  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.844560    0.800000  0.828859    0.822280      0.827513\n",
      "recall       0.885870    0.736842  0.828859    0.811356      0.828859\n",
      "f1-score     0.864721    0.767123  0.828859    0.815922      0.827385\n",
      "support    184.000000  114.000000  0.828859  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.793269    0.788889  0.791946    0.791079      0.791594\n",
      "recall       0.896739    0.622807  0.791946    0.759773      0.791946\n",
      "f1-score     0.841837    0.696078  0.791946    0.768958      0.786077\n",
      "support    184.000000  114.000000  0.791946  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.803109    0.723810  0.775168    0.763459      0.772773\n",
      "recall       0.842391    0.666667  0.775168    0.754529      0.775168\n",
      "f1-score     0.822281    0.694064  0.775168    0.758173      0.773232\n",
      "support    184.000000  114.000000  0.775168  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.780488    0.741935  0.768456    0.761212      0.765740\n",
      "recall       0.869565    0.605263  0.768456    0.737414      0.768456\n",
      "f1-score     0.822622    0.666667  0.768456    0.744644      0.762961\n",
      "support    184.000000  114.000000  0.768456  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.811518    0.728972  0.781879    0.770245      0.779940\n",
      "recall       0.842391    0.684211  0.781879    0.763301      0.781879\n",
      "f1-score     0.826667    0.705882  0.781879    0.766275      0.780461\n",
      "support    184.000000  114.000000  0.781879  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.752294    0.750000  0.751678    0.751147      0.751416\n",
      "recall       0.891304    0.526316  0.751678    0.708810      0.751678\n",
      "f1-score     0.815920    0.618557  0.751678    0.717239      0.740419\n",
      "support    184.000000  114.000000  0.751678  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 11\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.794872    0.718447  0.768456    0.756659      0.765635\n",
      "recall       0.842391    0.649123  0.768456    0.745757      0.768456\n",
      "f1-score     0.817942    0.682028  0.768456    0.749985      0.765948\n",
      "support    184.000000  114.000000  0.768456  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 12\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.754717    0.72093  0.744966    0.737824      0.741792\n",
      "recall       0.869565    0.54386  0.744966    0.706712      0.744966\n",
      "f1-score     0.808081    0.62000  0.744966    0.714040      0.736130\n",
      "support    184.000000  114.00000  0.744966  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 13\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.768844    0.686869  0.741611    0.727856      0.737484\n",
      "recall       0.831522    0.596491  0.741611    0.714006      0.741611\n",
      "f1-score     0.798956    0.638498  0.741611    0.718727      0.737572\n",
      "support    184.000000  114.000000  0.741611  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 14\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.736111    0.695122  0.724832    0.715617      0.720431\n",
      "recall       0.864130    0.500000  0.724832    0.682065      0.724832\n",
      "f1-score     0.795000    0.581633  0.724832    0.688316      0.713376\n",
      "support    184.000000  114.000000  0.724832  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 15\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.750000    0.584746  0.684564    0.667373      0.686782\n",
      "recall       0.733696    0.605263  0.684564    0.669479      0.684564\n",
      "f1-score     0.741758    0.594828  0.684564    0.668293      0.685550\n",
      "support    184.000000  114.000000  0.684564  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 16\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.719212    0.600000  0.681208    0.659606      0.673607\n",
      "recall       0.793478    0.500000  0.681208    0.646739      0.681208\n",
      "f1-score     0.754522    0.545455  0.681208    0.649988      0.674543\n",
      "support    184.000000  114.000000  0.681208  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 17\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.735450    0.587156  0.681208    0.661303      0.678720\n",
      "recall       0.755435    0.561404  0.681208    0.658419      0.681208\n",
      "f1-score     0.745308    0.573991  0.681208    0.659650      0.679771\n",
      "support    184.000000  114.000000  0.681208  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 18\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.725962    0.633333  0.697987    0.679647      0.690527\n",
      "recall       0.820652    0.500000  0.697987    0.660326      0.697987\n",
      "f1-score     0.770408    0.558824  0.697987    0.664616      0.689466\n",
      "support    184.000000  114.000000  0.697987  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 19\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.736842    0.592593  0.684564    0.664717      0.681659\n",
      "recall       0.760870    0.561404  0.684564    0.661137      0.684564\n",
      "f1-score     0.748663    0.576577  0.684564    0.662620      0.682831\n",
      "support    184.000000  114.000000  0.684564  298.000000    298.000000\n",
      "\n",
      "KNN Model with # of nearest neighbors: 20\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.736585    0.645161  0.708054    0.690873      0.701611\n",
      "recall       0.820652    0.526316  0.708054    0.673484      0.708054\n",
      "f1-score     0.776350    0.579710  0.708054    0.678030      0.701125\n",
      "support    184.000000  114.000000  0.708054  298.000000    298.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise #4. Run through steps 2-4 setting k to 10\n",
    "# Exercise #5. Run through steps 2-4 setting k to 20\n",
    "# can combine these two (2) steps/exercises with a \"for loop\" and range function\n",
    "\n",
    "# using for loops to create classification reports for all depth 1-15\n",
    "\n",
    "for k in range(1, 21):\n",
    "    # Making the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n",
    "\n",
    "    # Fitting the model (on train and only train data)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "\n",
    "    # Using the model\n",
    "    # We'll evaluate the model's performance on train, first:\n",
    "    y_predictions = knn.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"KNN Model with # of nearest neighbors: {k}\")\n",
    "    print(pd.DataFrame(report))\n",
    "\n",
    "    print() # printing a indented line for ea. iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_neighbors</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>percent_change_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_of_neighbors  train_accuracy  validate_accuracy  percent_change_diff\n",
       "0                  1            0.90               0.59                 0.35\n",
       "1                  2            0.81               0.63                 0.23\n",
       "2                  3            0.84               0.68                 0.19\n",
       "3                  4            0.83               0.68                 0.18\n",
       "4                  5            0.83               0.69                 0.16\n",
       "5                  6            0.79               0.67                 0.16\n",
       "6                  7            0.78               0.67                 0.14\n",
       "7                  8            0.77               0.68                 0.12\n",
       "8                  9            0.78               0.67                 0.15\n",
       "9                 10            0.75               0.68                 0.10\n",
       "10                11            0.77               0.64                 0.17\n",
       "11                12            0.74               0.68                 0.09\n",
       "12                13            0.74               0.68                 0.08\n",
       "13                14            0.72               0.72                 0.01\n",
       "14                15            0.68               0.67                 0.03\n",
       "15                16            0.68               0.64                 0.06\n",
       "16                17            0.68               0.64                 0.06\n",
       "17                18            0.70               0.64                 0.08\n",
       "18                19            0.68               0.61                 0.10\n",
       "19                20            0.71               0.67                 0.06"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "for k in range(1, 21):\n",
    "    # Make the model\n",
    "    knn = KNeighborsClassifier(n_neighbors= k, weights = 'uniform')\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = knn.score(X_train, y_train)\n",
    "    \n",
    "    # next, we'll evaluate the model on \"out-of-sample\" data (validate)\n",
    "    out_of_sample_accuracy = knn.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"num_of_neighbors\": k,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"percent_change_diff\"] = ((df.train_accuracy - df.validate_accuracy) / df.train_accuracy)\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.percent_change_diff.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_of_neighbors       20.000000\n",
       "train_accuracy          0.899329\n",
       "validate_accuracy       0.720000\n",
       "percent_change_diff     0.347662\n",
       "dtype: float64"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "col_max = df.max(axis = 0)\n",
    "col_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_of_neighbors</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.899329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.808725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.842282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.825503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.828859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.791946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.775168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.768456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.781879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.751678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.768456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.744966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.741611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.724832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.684564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.681208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.681208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.697987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.684564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.708054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train_accuracy\n",
       "num_of_neighbors                \n",
       "1                       0.899329\n",
       "2                       0.808725\n",
       "3                       0.842282\n",
       "4                       0.825503\n",
       "5                       0.828859\n",
       "6                       0.791946\n",
       "7                       0.775168\n",
       "8                       0.768456\n",
       "9                       0.781879\n",
       "10                      0.751678\n",
       "11                      0.768456\n",
       "12                      0.744966\n",
       "13                      0.741611\n",
       "14                      0.724832\n",
       "15                      0.684564\n",
       "16                      0.681208\n",
       "17                      0.681208\n",
       "18                      0.697987\n",
       "19                      0.684564\n",
       "20                      0.708054"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"num_of_neighbors\"])[[\"train_accuracy\"]].max()\n",
    "\n",
    "# here we see that when number of neighbors is equal to 1, the highest train accuracy is returned: ~90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick comparison check:\n",
    "\n",
    "(df[\"validate_accuracy\"] > df[\"train_accuracy\"]) == True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions:\n",
    " \n",
    "**7. Which model performs best on our out-of-sample data from validate?**\n",
    "\n",
    "<u>depends on how \"best\" is defined:</u>\n",
    "\n",
    "- however, performance of my model is \"relatively most\" optimal when the number of nearest neighbor hyper-parameter is **20**. In this case, the model will have the least variability across the in-sample and out-sample datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Logistical Regression Module Exercises:\n",
    "\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n",
    "\n",
    "1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?\n",
    "\n",
    "2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n",
    "\n",
    "3. Try out other combinations of features and models.\n",
    "\n",
    "4. Use you best 3 models to predict and evaluate on your validate sample.\n",
    "\n",
    "5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n",
    "\n",
    "**Bonus1:** How do different strategies for handling the missing values in the age column affect model performance?\n",
    "\n",
    "**Bonus2:** How do different strategies for encoding sex affect model performance?\n",
    "\n",
    "Bonus3: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "\n",
    "C = 0.01, .1, 1, 10, 100, 1000\n",
    "\n",
    "\n",
    "**Bonus Bonus:** how does scaling the data interact with your choice of C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries/modules\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the Pandas max row/columns option to none\n",
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the titanic dataset\n",
    "\n",
    "titanic_df = get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a titanic_df copy\n",
    "\n",
    "titanic_copy = titanic_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Missing values heatmap')"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting missing values\n",
    "\n",
    "titanic_copy.isnull().sum()\n",
    "sns.heatmap(titanic_copy.isnull(), cbar = False).set_title(\"Missing values heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id    0.00\n",
       "survived        0.00\n",
       "pclass          0.00\n",
       "sex             0.00\n",
       "age             0.20\n",
       "sibsp           0.00\n",
       "parch           0.00\n",
       "fare            0.00\n",
       "embarked        0.00\n",
       "class           0.00\n",
       "deck            0.77\n",
       "embark_town     0.00\n",
       "alone           0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where 20% of our age values are missing\n",
    "\n",
    "round(titanic_copy.isna().mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.  , 38.  , 26.  , 35.  ,   nan, 54.  ,  2.  , 27.  , 14.  ,\n",
       "        4.  , 58.  , 20.  , 39.  , 55.  , 31.  , 34.  , 15.  , 28.  ,\n",
       "        8.  , 19.  , 40.  , 66.  , 42.  , 21.  , 18.  ,  3.  ,  7.  ,\n",
       "       49.  , 29.  , 65.  , 28.5 ,  5.  , 11.  , 45.  , 17.  , 32.  ,\n",
       "       16.  , 25.  ,  0.83, 30.  , 33.  , 23.  , 24.  , 46.  , 59.  ,\n",
       "       71.  , 37.  , 47.  , 14.5 , 70.5 , 32.5 , 12.  ,  9.  , 36.5 ,\n",
       "       51.  , 55.5 , 40.5 , 44.  ,  1.  , 61.  , 56.  , 50.  , 36.  ,\n",
       "       45.5 , 20.5 , 62.  , 41.  , 52.  , 63.  , 23.5 ,  0.92, 43.  ,\n",
       "       60.  , 10.  , 64.  , 13.  , 48.  ,  0.75, 53.  , 57.  , 80.  ,\n",
       "       70.  , 24.5 ,  6.  ,  0.67, 30.5 ,  0.42, 34.5 , 74.  ])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy.age.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean age value for all passengers\n",
    "\n",
    "titanic_copy.age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    passenger_id  survived  pclass     sex  age  sibsp  parch     fare  \\\n",
       "5              5         0       3    male  NaN      0      0   8.4583   \n",
       "17            17         1       2    male  NaN      0      0  13.0000   \n",
       "19            19         1       3  female  NaN      0      0   7.2250   \n",
       "26            26         0       3    male  NaN      0      0   7.2250   \n",
       "28            28         1       3  female  NaN      0      0   7.8792   \n",
       "\n",
       "   embarked   class deck  embark_town  alone  \n",
       "5         Q   Third  NaN   Queenstown      1  \n",
       "17        S  Second  NaN  Southampton      1  \n",
       "19        C   Third  NaN    Cherbourg      1  \n",
       "26        C   Third  NaN    Cherbourg      1  \n",
       "28        Q   Third  NaN   Queenstown      1  "
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the missing \"age values\"\n",
    "\n",
    "bool_series = pd.isnull(titanic_copy[\"age\"])\n",
    "missing_age = titanic_copy[bool_series]\n",
    "missing_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    125\n",
       "1     52\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy[bool_series].survived.value_counts()\n",
    "\n",
    "# passengers with missing age values: \n",
    "# 125 did NOT survive\n",
    "# 52 survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sex       female  male\n",
       "survived              \n",
       "0          0.096  0.61\n",
       "1          0.203  0.09"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(missing_age.survived, missing_age.sex, normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in the missing age values\n",
    "\n",
    "titanic_copy = titanic_copy.fillna(titanic_copy.mean().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id    0\n",
       "survived        0\n",
       "pclass          0\n",
       "sex             0\n",
       "age             0\n",
       "sibsp           0\n",
       "parch           0\n",
       "fare            0\n",
       "embarked        0\n",
       "class           0\n",
       "deck            0\n",
       "embark_town     0\n",
       "alone           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>445.0</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>445.0</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>445.0</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class   deck  embark_town  alone  \n",
       "0        S  Third  445.0  Southampton      0  \n",
       "1        C  First      C    Cherbourg      0  \n",
       "2        S  Third  445.0  Southampton      1  \n",
       "3        S  First      C  Southampton      0  \n",
       "4        S  Third  445.0  Southampton      1  "
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_copy = titanic_copy.drop(columns=[\"passenger_id\", \"embarked\", \"pclass\", \"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_copy[\"fare\"] = titanic_copy[\"fare\"].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (534, 12)\n",
      "Validate dataset shape: (178, 12)\n",
      "Test dataset shape: (179, 12)\n"
     ]
    }
   ],
   "source": [
    "titanic_copy = pd.get_dummies(titanic_copy, columns = ['sex', 'class', 'embark_town'], drop_first = True)\n",
    "titanic_copy.head()\n",
    "\n",
    "# 1st split:\n",
    "\n",
    "def split_data(df):\n",
    "    '''\n",
    "    Takes in a dataframe and return train, validate, test subset dataframes\n",
    "    '''\n",
    "    train, test = train_test_split(df, test_size = 0.2, random_state=123, stratify = df.sex_male)\n",
    "    train, validate = train_test_split(train, test_size= 0.25, random_state=123, stratify = train.sex_male)\n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = split_data(titanic_copy)\n",
    "\n",
    "print(f\"Train dataset shape: {train.shape}\")\n",
    "print(f\"Validate dataset shape: {validate.shape}\")\n",
    "print(f\"Test dataset shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived    age  sibsp  parch   fare  alone  sex_male  class_Second  \\\n",
       "142         1   24.0      1      0  15.85      0         0             0   \n",
       "827         1    1.0      0      2  37.00      0         1             1   \n",
       "865         1   42.0      0      0  13.00      1         0             1   \n",
       "531         0  445.0      0      0   7.23      1         1             0   \n",
       "292         0   36.0      0      0  12.88      1         1             1   \n",
       "\n",
       "     class_Third  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "142            1                      0                       0   \n",
       "827            0                      1                       0   \n",
       "865            0                      0                       0   \n",
       "531            1                      1                       0   \n",
       "292            0                      1                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "142                        1  \n",
       "827                        0  \n",
       "865                        1  \n",
       "531                        0  \n",
       "292                        0  "
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd split:\n",
    "\n",
    "X = train[[ \n",
    "    'fare', \\\n",
    "    'class_Second', \\\n",
    "    'class_Third', \\\n",
    "    'age']]\n",
    "\n",
    "y = train[\"survived\"]\n",
    "\n",
    "X_train_and_validate, X_test, y_train_and_validate, y_test = train_test_split(X, y, random_state=123, test_size=.3)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_and_validate, y_train_and_validate, random_state=123, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the first model:\n",
    "\n",
    "logit1 = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model:\n",
    "\n",
    "logit1 = logit1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the model to make predictions of y\n",
    "\n",
    "y_predictions = logit1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirming \"classes\" attributes:\n",
    "\n",
    "logit1.classes_ # checks out (0 = did not survive and 1 = survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.75       184\n",
      "           1       0.60      0.68      0.64       114\n",
      "\n",
      "    accuracy                           0.70       298\n",
      "   macro avg       0.69      0.70      0.69       298\n",
      "weighted avg       0.71      0.70      0.70       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #2: including \n",
    "\n",
    "# 2nd split:\n",
    "\n",
    "\n",
    "X = train[[ \n",
    "    'fare', \\\n",
    "    'class_Second', \\\n",
    "    'class_Third', \\\n",
    "    'sex_male', \\\n",
    "    'age']]\n",
    "\n",
    "y = train[\"survived\"]\n",
    "\n",
    "X_train_and_validate, X_test, y_train_and_validate, y_test = train_test_split(X, y, random_state=123, test_size=.3)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_and_validate, y_train_and_validate, random_state=123, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the model class \"logistical regression\"\n",
    "\n",
    "logit2 = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model:\n",
    "\n",
    "logit2 = logit2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the model to make predictions of y\n",
    "\n",
    "y_predictions = logit2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       184\n",
      "           1       0.67      0.54      0.60       114\n",
      "\n",
      "    accuracy                           0.72       298\n",
      "   macro avg       0.71      0.69      0.69       298\n",
      "weighted avg       0.72      0.72      0.71       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mijailmariano/codeup-data-science/classification-exercises/model.ipynb Cell 136'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mijailmariano/codeup-data-science/classification-exercises/model.ipynb#ch0000156?line=7'>8</a>\u001b[0m logit \u001b[39m=\u001b[39m LogisticRegression(C\u001b[39m=\u001b[39mi, random_state\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mijailmariano/codeup-data-science/classification-exercises/model.ipynb#ch0000156?line=9'>10</a>\u001b[0m \u001b[39m# Fitting the model (on train and only train)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mijailmariano/codeup-data-science/classification-exercises/model.ipynb#ch0000156?line=10'>11</a>\u001b[0m logit \u001b[39m=\u001b[39m logit\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mijailmariano/codeup-data-science/classification-exercises/model.ipynb#ch0000156?line=12'>13</a>\u001b[0m \u001b[39m# Using the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mijailmariano/codeup-data-science/classification-exercises/model.ipynb#ch0000156?line=13'>14</a>\u001b[0m \u001b[39m# We'll evaluate the model's performance on train, first:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mijailmariano/codeup-data-science/classification-exercises/model.ipynb#ch0000156?line=14'>15</a>\u001b[0m y_predictions \u001b[39m=\u001b[39m logit\u001b[39m.\u001b[39mpredict(X_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1589\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1588\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1589\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m   1590\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m   1591\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1592\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer),\n\u001b[1;32m   1593\u001b[0m )(\n\u001b[1;32m   1594\u001b[0m     path_func(\n\u001b[1;32m   1595\u001b[0m         X,\n\u001b[1;32m   1596\u001b[0m         y,\n\u001b[1;32m   1597\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1598\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1599\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1600\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1601\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1602\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1603\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1604\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1605\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1606\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1607\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1608\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1609\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1610\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1611\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1612\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1613\u001b[0m     )\n\u001b[1;32m   1614\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1615\u001b[0m )\n\u001b[1;32m   1617\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:811\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    803\u001b[0m     iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[1;32m    804\u001b[0m         np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)\n\u001b[1;32m    805\u001b[0m     ]\n\u001b[1;32m    806\u001b[0m     opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39mminimize(\n\u001b[1;32m    807\u001b[0m         func,\n\u001b[1;32m    808\u001b[0m         w0,\n\u001b[1;32m    809\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL-BFGS-B\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    810\u001b[0m         jac\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m--> 811\u001b[0m         args\u001b[39m=\u001b[39m(X, target, \u001b[39m1.0\u001b[39;49m \u001b[39m/\u001b[39;49m C, sample_weight),\n\u001b[1;32m    812\u001b[0m         options\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39miprint\u001b[39m\u001b[39m\"\u001b[39m: iprint, \u001b[39m\"\u001b[39m\u001b[39mgtol\u001b[39m\u001b[39m\"\u001b[39m: tol, \u001b[39m\"\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m\"\u001b[39m: max_iter},\n\u001b[1;32m    813\u001b[0m     )\n\u001b[1;32m    814\u001b[0m     n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    815\u001b[0m         solver,\n\u001b[1;32m    816\u001b[0m         opt_res,\n\u001b[1;32m    817\u001b[0m         max_iter,\n\u001b[1;32m    818\u001b[0m         extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    819\u001b[0m     )\n\u001b[1;32m    820\u001b[0m     w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "lst = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "x = 0\n",
    "\n",
    "while x < len(lst): \n",
    "    print(lst[x]) \n",
    "    x = x+1\n",
    "    # Making the model\n",
    "    logit = LogisticRegression(C=i, random_state=123)\n",
    "\n",
    "    # Fitting the model (on train and only train)\n",
    "    logit = logit.fit(X_train, y_train)\n",
    "\n",
    "    # Using the model\n",
    "    # We'll evaluate the model's performance on train, first:\n",
    "    y_predictions = logit.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Coefficient: {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "\n",
    "    print() # printing a indented line for ea. iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
